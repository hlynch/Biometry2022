library(RPostgres)
library(tidyverse)
con <- dbConnect(
RPostgres::Postgres(),
dbname = "landsat_qaqc",
host = "landsat-qaqc.crhzrobl6kz8.us-west-2.rds.amazonaws.com",
port = 5432,
user = "frontend",
password = "bushybeard",
sslmode = '')
sql <- "SELECT * FROM qaqc_l7;"
L7_C2_L1_site_scene_spectral_nodup_qaqc <- dbGetQuery(con, sql)
save(L7_C2_L1_site_scene_spectral_nodup_qaqc, file = "Library/L7_C2_L1_site_scene_spectral_nodup_qaqc.rda")
qaqc_summary <- L7_C2_L1_site_scene_spectral_nodup_qaqc %>%
dplyr::select(site_id, keep, dump, check_it, register) %>%
mutate(keep = as.integer(keep), dump = as.integer(dump), check_it = as.integer(check_it), register = as.integer(register)) %>%
mutate(processed = keep + dump) %>%
group_by(site_id) %>%
summarize(keep = sum(keep), dump = sum(dump), check_it = sum(check_it), register = sum(register), processed = sum(processed), n = n()) %>%
ungroup() %>%
mutate(complete = ifelse(processed == n & check_it == 0, 1, 0))
sum(qaqc_summary$processed) / sum(qaqc_summary$n)
runApp('Documents/Projects/Landsat_L8_cloud_clearing/ShinyApp/app_L7_png.R')
library(RPostgres)
library(tidyverse)
con <- dbConnect(
RPostgres::Postgres(),
dbname = "landsat_qaqc",
host = "landsat-qaqc.crhzrobl6kz8.us-west-2.rds.amazonaws.com",
port = 5432,
user = "frontend",
password = "bushybeard",
sslmode = '')
sql <- "SELECT * FROM qaqc_l7;"
L7_C2_L1_site_scene_spectral_nodup_qaqc <- dbGetQuery(con, sql)
save(L7_C2_L1_site_scene_spectral_nodup_qaqc, file = "Library/L7_C2_L1_site_scene_spectral_nodup_qaqc.rda")
qaqc_summary <- L7_C2_L1_site_scene_spectral_nodup_qaqc %>%
dplyr::select(site_id, keep, dump, check_it, register) %>%
mutate(keep = as.integer(keep), dump = as.integer(dump), check_it = as.integer(check_it), register = as.integer(register)) %>%
mutate(processed = keep + dump) %>%
group_by(site_id) %>%
summarize(keep = sum(keep), dump = sum(dump), check_it = sum(check_it), register = sum(register), processed = sum(processed), n = n()) %>%
ungroup() %>%
mutate(complete = ifelse(processed == n & check_it == 0, 1, 0))
sum(qaqc_summary$processed) / sum(qaqc_summary$n)
runApp('Documents/Projects/Landsat_L8_cloud_clearing/ShinyApp/app_L7_png.R')
library(RPostgres)
library(tidyverse)
con <- dbConnect(
RPostgres::Postgres(),
dbname = "landsat_qaqc",
host = "landsat-qaqc.crhzrobl6kz8.us-west-2.rds.amazonaws.com",
port = 5432,
user = "frontend",
password = "bushybeard",
sslmode = '')
sql <- "SELECT * FROM qaqc_l7;"
L7_C2_L1_site_scene_spectral_nodup_qaqc <- dbGetQuery(con, sql)
save(L7_C2_L1_site_scene_spectral_nodup_qaqc, file = "Library/L7_C2_L1_site_scene_spectral_nodup_qaqc.rda")
qaqc_summary <- L7_C2_L1_site_scene_spectral_nodup_qaqc %>%
dplyr::select(site_id, keep, dump, check_it, register) %>%
mutate(keep = as.integer(keep), dump = as.integer(dump), check_it = as.integer(check_it), register = as.integer(register)) %>%
mutate(processed = keep + dump) %>%
group_by(site_id) %>%
summarize(keep = sum(keep), dump = sum(dump), check_it = sum(check_it), register = sum(register), processed = sum(processed), n = n()) %>%
ungroup() %>%
mutate(complete = ifelse(processed == n & check_it == 0, 1, 0))
sum(qaqc_summary$processed) / sum(qaqc_summary$n)
library(RPostgres)
library(tidyverse)
con <- dbConnect(
RPostgres::Postgres(),
dbname = "landsat_qaqc",
host = "landsat-qaqc.crhzrobl6kz8.us-west-2.rds.amazonaws.com",
port = 5432,
user = "frontend",
password = "bushybeard",
sslmode = '')
sql <- "SELECT * FROM qaqc_l7;"
L7_C2_L1_site_scene_spectral_nodup_qaqc <- dbGetQuery(con, sql)
save(L7_C2_L1_site_scene_spectral_nodup_qaqc, file = "Library/L7_C2_L1_site_scene_spectral_nodup_qaqc.rda")
qaqc_summary <- L7_C2_L1_site_scene_spectral_nodup_qaqc %>%
dplyr::select(site_id, keep, dump, check_it, register) %>%
mutate(keep = as.integer(keep), dump = as.integer(dump), check_it = as.integer(check_it), register = as.integer(register)) %>%
mutate(processed = keep + dump) %>%
group_by(site_id) %>%
summarize(keep = sum(keep), dump = sum(dump), check_it = sum(check_it), register = sum(register), processed = sum(processed), n = n()) %>%
ungroup() %>%
mutate(complete = ifelse(processed == n & check_it == 0, 1, 0))
sum(qaqc_summary$processed) / sum(qaqc_summary$n)
library(shiny); runApp('Documents/Projects/Landsat_L8_cloud_clearing/ShinyApp/app_L7_png.R')
1.7/6.5
(1.04)^30
(1.01)^30
(1.02)^30
(1.015)^30
(1.015)^100
2946.37*2
99.23*2
3274+955+280+25000+150+12630+40000+8500+25000+175250+6430+13550+35000+450
1151.27*2
phat<-2000/2000000
1.96*sqrt((phat*(1-phat))/2000000)
phat-1.96*sqrt((phat*(1-phat))/2000000)
phat+1.96*sqrt((phat*(1-phat))/2000000)
3120+99+209+43+356+16
hist(rbeta(1000,43,57))
hist(rbeta(1000,82,18))
47858+1138+6532
library(devtools)
install_github("Zoological-Society-of-London/rlpi", dependencies=TRUE)
library(rlpi)
setwd("~/Dropbox/Pew Marine Fellowship")
# Get example data from package
# Copy zipped data to local directory
file.copy(from=system.file("extdata", "example_data.zip", package = "rlpi"), to=getwd())
unzip("example_data.zip")
Nearc_lpi <- LPIMain("example_data/terrestrial_class_nearctic_infile.txt", use_weightings = 1, VERBOSE=FALSE, show_progress=FALSE)
?LPIMain
Nearc_lpi <- LPIMain("example_data/terrestrial_class_nearctic_infile.txt", use_weightings = 1, VERBOSE=FALSE)
# Remove NAs (trailing years with no data)
Nearc_lpi <- Nearc_lpi[complete.cases(Nearc_lpi), ]
# This produces a simple plot, but we can use ggplot_lpi to produce a nicer version
ggplot_lpi(Nearc_lpi, ylims=c(0, 2))
View(Nearc_lpi)
library(readxl)
LPI_test <- read_excel("LPI_test.xlsx")
View(LPI_test)
model <- mgcv::gam(log(LPI_test$popvalue) ~ s(LPI_test$year, k = 20), fx = TRUE)
model
plot(model, pages = 1, residuals = TRUE, all.terms = TRUE, shade = TRUE,
shade.col = 2)
Test_lpi <- LPIMain(LPI_test, use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
getwd()
Test_lpi <- LPIMain("LPI_test.xlsx", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
Test_lpi <- LPIMain("LPI_test.txt", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
warnings()
Test_lpi <- LPIMain("LPI_test.txt", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
warnings()
Test_lpi <- LPIMain("LPI_test.txt", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
Test_lpi <- LPIMain("LPI_test.txt", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
Test_lpi <- LPIMain("LPI_test.txt", use_weightings = 1, VERBOSE=TRUE,MODEL_SELECTION_FLAG = 1)
?create_infile
LPI_index<-as.dataframe(LPI_index)
LPI_index<-as.data.frame(LPI_index)
LPI_test<-as.data.frame(LPI_test)
create_infile(LPI_test)
library(readxl)
LPI_test <- read_excel("LPI_test.xlsx")
View(LPI_test)
example_infile_name <- create_infile(LPI_test, index_vector=index_vector, name="example_data")
index_vector = rep(FALSE, nrow(lpi_data))
index_vector[1:100] = TRUE
index_vector = rep(FALSE, nrow(LPI_test))
index_vector[1:100] = TRUE
example_infile_name <- create_infile(LPI_test, index_vector=index_vector, name="example_data")
rnow(LPI_test)
LPI_test
library(readr)
LPI_test <- read_csv("LPI_test.csv")
View(LPI_test)
library(readr)
LPI_test <- read_csv("LPI_test.csv")
View(LPI_test)
example_infile_name <- create_infile(LPI_test, index_vector=index_vector, name="example_data")
index_vector = rep(FALSE, nrow(LPI_test))
index_vector[1] = TRUE
example_infile_name <- create_infile(LPI_test, index_vector=index_vector, name="example_data")
nrow9LPI_data
nrow(LPI_data)
nrow(LPI_test)
?create_infile
example_infile_name <- create_infile(LPI_test)
dim(LPI_test)
LPI_test[1,50:55]
LPI_test[1,60:65]
LPI_test[1,70:75]
example_infile_name <- create_infile(LPI_test,start_col_name = "1977",end_col_name="2019")
LPIMain(example_infile_name)
example_infile_name
LPIMain(example_infile)
example_infile <- create_infile(LPI_test,start_col_name = "1977",end_col_name="2019")
LPIMain(example_infile)
example_infile
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE, show_progress=FALSE)
?LPIMain
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 4))
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 2))
chinstrap_lpi
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2010, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2010), ylim=c(0, 2))
chinstrap_lpi
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2009), ylim=c(0, 2))
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2009, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2009), ylim=c(0, 2))
?ggplot_lpi
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2009), ylim=c(0, 4))
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2009), ylim=c(0, 6))
chinstrap_lpi
View(chinstrap_lpi_data)
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2009, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2009), ylim=c(0, 6))
chinstrap_lpi
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
chinstrap_lpi
?LPIMain
ggplot_lpi(chinstrap_lpi)
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 2000, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
chinstrap_lpi
setwd("~/Dropbox/Pew Marine Fellowship")
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
View(chinstrap_lpi_data)
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
library(rlpi)
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
LPIMain()
LPIMain
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1980, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
SpeciesLambdaArray = data.frame(NULL)
SpeciesLambdaArray = data.frame(NULL)
FileName = file.path("~/Dropbox/Pew Marine Fellowship/lpi_temp/3c4f56f2891cbd6bc4c7c36ca037038c_splambda.csv")
SpeciesLambda = read.table(FileName, header = FALSE, sep = ",")
SpeciesLambdaArray <- plyr::rbind.fill(SpeciesLambdaArray, SpeciesLambda)
SpeciesLambdaArray = data.frame(NULL)
FileName = file.path("~/Dropbox/Pew Marine Fellowship/lpi_temp/3c4f56f2891cbd6bc4c7c36ca037038c_splambda.csv")
SpeciesLambda = read.table(FileName, header = FALSE, sep = ",")
SpeciesLambdaArray <- plyr::rbind.fill(SpeciesLambdaArray, SpeciesLambda)
fileindex = NULL
FileNo<-1
fileindex = c(fileindex, rep(FileNo, dim(SpeciesLambda)[1]))
PLOT_MAX = 2017
REF_YEAR = 1980
DSize = PLOT_MAX - REF_YEAR + 2
Group=1
Weightings=1
use_weightings=0
use_weightings_B=0
WeightingsB=NULL
CAP_LAMBDAS = TRUE
NoFiles = length(unique(fileindex))
NoGroups = length(unique(Group[[1]]))
BootI = matrix(0, DSize)
BootI[1] = 1
cat(".")
# For each year
for (J in 2:DSize) {
# Make two matrices of 0s of size 1xNoGroups
D = matrix(0, 1, NoGroups)
DI = matrix(0, 1, NoGroups)
# For each file (population) in this file/set of species lambdas
for (FileNo in 1:NoFiles) {
GroupNo = Group[FileNo, 1]
# Read SpeciesLambda from saved file FileName = paste('lpi_temp/SpeciesLambda',FileNo,sep='')
# SpeciesLambda = read.table(FileName, header = FALSE, sep=',')
SpeciesLambda = SpeciesLambdaArray[fileindex == FileNo, J]
if(!is.null(SpeciesLambda)) {
# We shouldn't be sampling missing values....
SpeciesLambdaVal = na.omit(SpeciesLambda)
# Create sample with replacement (single bootstrap instance)
BootVal <- sample(SpeciesLambdaVal, replace = T)
# If we've got some meaningful data
if (!CAP_LAMBDAS) {
Index = which(BootVal != -1)
} else {
Index = which(!is.na(BootVal))
}
if (length(Index) > 0) {
# Store sum of mean lamdas in D (summing over species within group)
#D[Group[FileNo, 1]] = D[Group[FileNo, 1]] + mean(BootVal[Index])
if (use_weightings) {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])*Weightings[[1]][FileNo]
} else {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])
}
DI[GroupNo] = DI[GroupNo] + 1
}
}
}
for (DIndex in 1:length(D)) {
if (use_weightings == 1) {
if (DI[DIndex] > 1) DI[DIndex] = 1
}
if (DI[DIndex] > 0) {
D[DIndex] = D[DIndex]/DI[DIndex]
} else {
D[DIndex] = 0
}
}
DT = 0
DI = 0
# Sum over groups
for (GroupNo in 1:NoGroups) {
# CHANGED AS D CAN BE 0 I.E ZERO GROWTH (AVERAGED)
#if (D[GroupNo] != 0) {
if (use_weightings_B == 1) {
# Catch any groups which have no data.
if (!is.na(D[GroupNo])) {
DT = DT + D[GroupNo]*WeightingsB[GroupNo]
#DI = DI + 1
}
DI = 1
} else {
# Catch any groups which have no data.
if (!is.na(D[GroupNo])) {
DT = DT + D[GroupNo]
DI = DI + 1
}
}
#}
}
if (DI == 0) {
# If there was no data in this run, set to -1
BootI[J] = -1
BootI[J] = NA
} else {
if (is.na( BootI[J - 1])) {
BootI[J] = 1 * 10^(DT/DI)
} else {
BootI[J] = BootI[J - 1] * 10^(DT/DI)
}
#BootI[J] = BootI[J - 1] * 10^(DT/DI)
}
}
#cat("BootI: ", BootI, "\n")
return(BootI)
}
NoFiles = length(unique(fileindex))
NoGroups = length(unique(Group[[1]]))
# Initialise first BootI for this loop to 1
BootI = matrix(0, DSize)
BootI[1] = 1
cat(".")
NoFiles
NoGroups
DSize
J=2
D = matrix(0, 1, NoGroups)
DI = matrix(0, 1, NoGroups)
# For each file (population) in this file/set of species lambdas
for (FileNo in 1:NoFiles) {
GroupNo = Group[FileNo, 1]
# Read SpeciesLambda from saved file FileName = paste('lpi_temp/SpeciesLambda',FileNo,sep='')
# SpeciesLambda = read.table(FileName, header = FALSE, sep=',')
SpeciesLambda = SpeciesLambdaArray[fileindex == FileNo, J]
if(!is.null(SpeciesLambda)) {
# We shouldn't be sampling missing values....
SpeciesLambdaVal = na.omit(SpeciesLambda)
# Create sample with replacement (single bootstrap instance)
BootVal <- sample(SpeciesLambdaVal, replace = T)
# If we've got some meaningful data
if (!CAP_LAMBDAS) {
Index = which(BootVal != -1)
} else {
Index = which(!is.na(BootVal))
}
if (length(Index) > 0) {
# Store sum of mean lamdas in D (summing over species within group)
#D[Group[FileNo, 1]] = D[Group[FileNo, 1]] + mean(BootVal[Index])
if (use_weightings) {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])*Weightings[[1]][FileNo]
} else {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])
}
DI[GroupNo] = DI[GroupNo] + 1
}
}
}
FileNo
dim(Group)
Group
NoGroups = length(unique(Group[[1]]))
NoGroups
length(Group)
Group[[1]]
Group[1]
dim(Group)
max(dim(Group))
FileTable = read.table("~/Dropbox/Pew Marine Fellowship/chinstrap_data_infile.txt", header = TRUE)
FileTable
Group = FileTable[2]
Group
dim(Group)
NoFiles = length(unique(fileindex))
NoGroups = length(unique(Group[[1]]))
# Initialise first BootI for this loop to 1
BootI = matrix(0, DSize)
BootI[1] = 1
cat(".")
J=2
D = matrix(0, 1, NoGroups)
DI = matrix(0, 1, NoGroups)
# For each file (population) in this file/set of species lambdas
for (FileNo in 1:NoFiles) {
GroupNo = Group[FileNo, 1]
# Read SpeciesLambda from saved file FileName = paste('lpi_temp/SpeciesLambda',FileNo,sep='')
# SpeciesLambda = read.table(FileName, header = FALSE, sep=',')
SpeciesLambda = SpeciesLambdaArray[fileindex == FileNo, J]
if(!is.null(SpeciesLambda)) {
# We shouldn't be sampling missing values....
SpeciesLambdaVal = na.omit(SpeciesLambda)
# Create sample with replacement (single bootstrap instance)
BootVal <- sample(SpeciesLambdaVal, replace = T)
# If we've got some meaningful data
if (!CAP_LAMBDAS) {
Index = which(BootVal != -1)
} else {
Index = which(!is.na(BootVal))
}
if (length(Index) > 0) {
# Store sum of mean lamdas in D (summing over species within group)
#D[Group[FileNo, 1]] = D[Group[FileNo, 1]] + mean(BootVal[Index])
if (use_weightings) {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])*Weightings[[1]][FileNo]
} else {
D[GroupNo] = D[GroupNo] + mean(BootVal[Index])
}
DI[GroupNo] = DI[GroupNo] + 1
}
}
}
# For each D
# Take average if there's values (otherwise 0) - so this gives group average
for (DIndex in 1:length(D)) {
if (use_weightings == 1) {
if (DI[DIndex] > 1) DI[DIndex] = 1
}
if (DI[DIndex] > 0) {
D[DIndex] = D[DIndex]/DI[DIndex]
} else {
D[DIndex] = 0
}
}
FileName = file.path("~/Dropbox/Pew Marine Fellowship/lpi_temp/3c4f56f2891cbd6bc4c7c36ca037038c_splambda.csv")
SpeciesLambda = read.table(FileName, header = FALSE, sep = ",")
SpeciesLambdaArray <- plyr::rbind.fill(SpeciesLambdaArray, SpeciesLambda)
View(SpeciesLambdaArray)
View(SpeciesLambda)
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1980, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
chinstrap_lpi_data <- read.csv("Chinstrap_LPI_data.csv", na.strings = "NULL")
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1980, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
chinstrap_infile <- create_infile(chinstrap_lpi_data, name="chinstrap_data")
chinstrap_lpi <- LPIMain(chinstrap_infile, REF_YEAR = 1970, PLOT_MAX = 2017, BOOT_STRAP_SIZE = 100, VERBOSE=FALSE)
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 6))
ggplot_lpi(chinstrap_lpi, title = "chinstrap_lpi", xlims=c(1970, 2017), ylim=c(0, 8))
setwd("~/Documents/Projects/Biometry2022")
bookdown::render_book("index.Rmd")
34/26
exp(6)
10^6
setwd("~/Documents/Projects/Biometry2022")
bookdown::render_book("index.Rmd")
setwd("~/Documents/Projects/Biometry2022")
bookdown::render_book("index.Rmd")
setwd("~/Documents/Projects/Biometry2022")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
17553/2
167683/21
library(mapppdr)
vignette(mapppdr)
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE") %>%
left_join(sites, by = "site_id")
head(chinstrap_counts)
library(tidyverse)
library(RefManageR)
library(sf)
library(htmlwidgets)
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE") %>%
left_join(sites, by = "site_id")
head(chinstrap_counts)
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE")
head(chinstrap_counts)
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE") %>%
left_join(sites, by = "site_id")
chinstrap_sites<-unique(chinstrap_counts$site_name)
head(chinstrap_sites)
length(chinstrap_sites)
min(chinstrap_counts$season)
hist(chinstrap_counts$season)
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE" & year %in$ c(1950,2021)) %>%
left_join(sites, by = "site_id")
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE" & season %in% c(1950:2021) %>%
left_join(sites, by = "site_id")
chinstrap_counts <- penguin_obs %>%
dplyr::filter(type == "nests" & species_id == "CHPE" & season %in% c(1950:2021)) %>%
left_join(sites, by = "site_id")
chinstrap_sites<-unique(chinstrap_counts$site_name)
